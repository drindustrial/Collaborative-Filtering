{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.abspath(os.getcwd())\n",
    "path = path[:path.rfind('\\\\') + 1]\n",
    "DATA_PATH = path + \"data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"D:/github/AML_DS_1/data/collaborative-filtering/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = train['rating'].values\n",
    "userIds = train['userId'].values\n",
    "itemIds = train['movieId'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implement a basic Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "n_users = np.max(userIds) + 1\n",
    "n_items = np.max(itemIds) + 1\n",
    "\n",
    "R = coo_matrix((ratings, (userIds, itemIds)), shape=(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: MSE = 2.521747633619708, lr = 159.68\n",
      "epoch 1: MSE = 1.9988046006617564, lr = 159.36064000000002\n",
      "epoch 2: MSE = 1.841907768948729, lr = 159.04191872\n",
      "epoch 3: MSE = 1.755406206445886, lr = 158.72383488256\n",
      "epoch 4: MSE = 1.6979857562988547, lr = 158.40638721279487\n",
      "epoch 5: MSE = 1.6560620875959688, lr = 158.08957443836928\n",
      "epoch 6: MSE = 1.6236869307936002, lr = 157.77339528949256\n",
      "epoch 7: MSE = 1.5976582223206295, lr = 157.45784849891356\n",
      "epoch 8: MSE = 1.5761514121635107, lr = 157.14293280191575\n",
      "epoch 9: MSE = 1.557954388901553, lr = 156.8286469363119\n",
      "epoch 10: MSE = 1.5423093124961418, lr = 156.51498964243928\n",
      "epoch 11: MSE = 1.5286352671788317, lr = 156.20195966315438\n",
      "epoch 12: MSE = 1.5165664184427587, lr = 155.88955574382808\n",
      "epoch 13: MSE = 1.5057808081957271, lr = 155.57777663234043\n",
      "epoch 14: MSE = 1.4960865175179654, lr = 155.26662107907575\n",
      "epoch 15: MSE = 1.4872859959573403, lr = 154.9560878369176\n",
      "epoch 16: MSE = 1.479273183464635, lr = 154.64617566124375\n",
      "epoch 17: MSE = 1.4719171004942648, lr = 154.33688330992126\n",
      "epoch 18: MSE = 1.4651566216850649, lr = 154.02820954330141\n",
      "epoch 19: MSE = 1.4588993980229832, lr = 153.72015312421482\n",
      "epoch 20: MSE = 1.45310850870935, lr = 153.4127128179664\n",
      "epoch 21: MSE = 1.4477156325810778, lr = 153.10588739233046\n",
      "epoch 22: MSE = 1.442697074482405, lr = 152.7996756175458\n",
      "epoch 23: MSE = 1.4380004893700558, lr = 152.4940762663107\n",
      "epoch 24: MSE = 1.433609515559172, lr = 152.1890881137781\n",
      "epoch 25: MSE = 1.4294831431268205, lr = 151.88470993755055\n",
      "epoch 26: MSE = 1.425609202909713, lr = 151.58094051767546\n",
      "epoch 27: MSE = 1.4219551965777046, lr = 151.2777786366401\n",
      "epoch 28: MSE = 1.4185114945566217, lr = 150.97522307936683\n",
      "epoch 29: MSE = 1.4152522551567728, lr = 150.6732726332081\n",
      "epoch 30: MSE = 1.4121695188962498, lr = 150.37192608794166\n",
      "epoch 31: MSE = 1.4092427633170996, lr = 150.07118223576578\n",
      "epoch 32: MSE = 1.4064652256679795, lr = 149.77103987129425\n",
      "epoch 33: MSE = 1.40382065553112, lr = 149.47149779155166\n",
      "epoch 34: MSE = 1.401303207451837, lr = 149.17255479596855\n",
      "epoch 35: MSE = 1.3989000418614794, lr = 148.87420968637662\n",
      "epoch 36: MSE = 1.3966060473250725, lr = 148.57646126700385\n",
      "epoch 37: MSE = 1.39441107714956, lr = 148.27930834446985\n",
      "epoch 38: MSE = 1.3923106232158589, lr = 147.9827497277809\n",
      "epoch 39: MSE = 1.3902966392310319, lr = 147.68678422832534\n",
      "epoch 40: MSE = 1.3883651233797085, lr = 147.39141065986868\n",
      "epoch 41: MSE = 1.3865096513310713, lr = 147.09662783854895\n",
      "epoch 42: MSE = 1.3847266548076569, lr = 146.80243458287185\n",
      "epoch 43: MSE = 1.3830109544065676, lr = 146.50882971370612\n",
      "epoch 44: MSE = 1.3813593603965812, lr = 146.2158120542787\n",
      "epoch 45: MSE = 1.379767647683027, lr = 145.92338043017014\n",
      "epoch 46: MSE = 1.378232962479622, lr = 145.6315336693098\n",
      "epoch 47: MSE = 1.376751813820782, lr = 145.34027060197116\n",
      "epoch 48: MSE = 1.3753216492616342, lr = 145.0495900607672\n",
      "epoch 49: MSE = 1.373939547023931, lr = 144.75949088064567\n",
      "epoch 50: MSE = 1.3726032262197787, lr = 144.46997189888438\n",
      "epoch 51: MSE = 1.3713102113280944, lr = 144.1810319550866\n",
      "epoch 52: MSE = 1.3700584660994553, lr = 143.89266989117644\n",
      "epoch 53: MSE = 1.3688458695953305, lr = 143.6048845513941\n",
      "epoch 54: MSE = 1.3676706051920697, lr = 143.3176747822913\n",
      "epoch 55: MSE = 1.366530837785266, lr = 143.03103943272671\n",
      "epoch 56: MSE = 1.365424946963198, lr = 142.74497735386126\n",
      "epoch 57: MSE = 1.3643513314010858, lr = 142.45948739915355\n",
      "epoch 58: MSE = 1.3633085451127696, lr = 142.17456842435524\n",
      "epoch 59: MSE = 1.362295180635532, lr = 141.89021928750654\n",
      "epoch 60: MSE = 1.3613099463853804, lr = 141.60643884893153\n",
      "epoch 61: MSE = 1.3603515976967748, lr = 141.32322597123368\n",
      "epoch 62: MSE = 1.3594189792394034, lr = 141.0405795192912\n",
      "epoch 63: MSE = 1.3585109845850087, lr = 140.75849836025264\n",
      "epoch 64: MSE = 1.3576265784184522, lr = 140.47698136353213\n",
      "epoch 65: MSE = 1.3567647728213248, lr = 140.19602740080506\n",
      "epoch 66: MSE = 1.3559246381179917, lr = 139.91563534600346\n",
      "epoch 67: MSE = 1.3551052888126929, lr = 139.63580407531146\n",
      "epoch 68: MSE = 1.3543058882446555, lr = 139.35653246716083\n",
      "epoch 69: MSE = 1.3535256400402267, lr = 139.0778194022265\n",
      "epoch 70: MSE = 1.3527637895275908, lr = 138.79966376342205\n",
      "epoch 71: MSE = 1.3520196183250877, lr = 138.5220644358952\n",
      "epoch 72: MSE = 1.3512924441519771, lr = 138.24502030702342\n",
      "epoch 73: MSE = 1.350581617208523, lr = 137.96853026640937\n",
      "epoch 74: MSE = 1.3498865192626228, lr = 137.69259320587656\n",
      "epoch 75: MSE = 1.3492065610720365, lr = 137.41720801946482\n",
      "epoch 76: MSE = 1.3485411812025871, lr = 137.14237360342588\n",
      "epoch 77: MSE = 1.3478898440778708, lr = 136.86808885621903\n",
      "epoch 78: MSE = 1.3472520387536349, lr = 136.5943526785066\n",
      "epoch 79: MSE = 1.3466272773654584, lr = 136.3211639731496\n",
      "epoch 80: MSE = 1.3460150939618245, lr = 136.0485216452033\n",
      "epoch 81: MSE = 1.3454150432210494, lr = 135.77642460191288\n",
      "epoch 82: MSE = 1.3448266993833748, lr = 135.50487175270905\n",
      "epoch 83: MSE = 1.3442496551627166, lr = 135.23386200920362\n",
      "epoch 84: MSE = 1.3436835207878857, lr = 134.96339428518522\n",
      "epoch 85: MSE = 1.3431279230639337, lr = 134.69346749661486\n",
      "epoch 86: MSE = 1.3425825045189268, lr = 134.42408056162162\n",
      "epoch 87: MSE = 1.342046922585532, lr = 134.1552324004984\n",
      "epoch 88: MSE = 1.3415208488443415, lr = 133.8869219356974\n",
      "epoch 89: MSE = 1.3410039683052033, lr = 133.619148091826\n",
      "epoch 90: MSE = 1.3404959787365878, lr = 133.35190979564234\n",
      "epoch 91: MSE = 1.3399965900313817, lr = 133.08520597605107\n",
      "epoch 92: MSE = 1.3395055236120033, lr = 132.81903556409898\n",
      "epoch 93: MSE = 1.3390225118686745, lr = 132.5533974929708\n",
      "epoch 94: MSE = 1.3385472976308783, lr = 132.28829069798485\n",
      "epoch 95: MSE = 1.338079633668362, lr = 132.02371411658888\n",
      "epoch 96: MSE = 1.337619282220639, lr = 131.7596666883557\n",
      "epoch 97: MSE = 1.3371660145525666, lr = 131.496147354979\n",
      "epoch 98: MSE = 1.3367196105346846, lr = 131.23315506026904\n",
      "epoch 99: MSE = 1.336279858246489, lr = 130.9706887501485\n",
      "epoch 100: MSE = 1.3358465536013415, lr = 130.7087473726482\n",
      "epoch 101: MSE = 1.3354194999915643, lr = 130.4473298779029\n",
      "epoch 102: MSE = 1.3349985079525242, lr = 130.18643521814707\n",
      "epoch 103: MSE = 1.3345833948444956, lr = 129.92606234771077\n",
      "epoch 104: MSE = 1.3341739845512461, lr = 129.66621022301536\n",
      "epoch 105: MSE = 1.3337701071943142, lr = 129.4068778025693\n",
      "epoch 106: MSE = 1.333371598862049, lr = 129.14806404696418\n",
      "epoch 107: MSE = 1.33297830135253, lr = 128.88976791887026\n",
      "epoch 108: MSE = 1.3325900619295445, lr = 128.63198838303254\n",
      "epoch 109: MSE = 1.332206733090875, lr = 128.37472440626647\n",
      "epoch 110: MSE = 1.3318281723481653, lr = 128.11797495745392\n",
      "epoch 111: MSE = 1.3314542420177122, lr = 127.86173900753901\n",
      "epoch 112: MSE = 1.3310848090215563, lr = 127.60601552952393\n",
      "epoch 113: MSE = 1.330719744698291, lr = 127.35080349846488\n",
      "epoch 114: MSE = 1.3303589246230474, lr = 127.09610189146795\n",
      "epoch 115: MSE = 1.3300022284361344, lr = 126.84190968768502\n",
      "epoch 116: MSE = 1.3296495396798766, lr = 126.58822586830965\n",
      "epoch 117: MSE = 1.3293007456431865, lr = 126.33504941657303\n",
      "epoch 118: MSE = 1.3289557372134455, lr = 126.08237931773988\n",
      "epoch 119: MSE = 1.3286144087353278, lr = 125.8302145591044\n",
      "epoch 120: MSE = 1.3282766578761633, lr = 125.5785541299862\n",
      "epoch 121: MSE = 1.3279423854975136, lr = 125.32739702172623\n",
      "epoch 122: MSE = 1.327611495532632, lr = 125.07674222768277\n",
      "epoch 123: MSE = 1.3272838948694887, lr = 124.8265887432274\n",
      "epoch 124: MSE = 1.3269594932390896, lr = 124.57693556574095\n",
      "epoch 125: MSE = 1.3266382031088026, lr = 124.32778169460947\n",
      "epoch 126: MSE = 1.326319939580439, lr = 124.07912613122025\n",
      "epoch 127: MSE = 1.32600462029286, lr = 123.83096787895781\n",
      "epoch 128: MSE = 1.3256921653288583, lr = 123.58330594319989\n",
      "epoch 129: MSE = 1.3253824971261239, lr = 123.33613933131349\n",
      "epoch 130: MSE = 1.3250755403920804, lr = 123.08946705265086\n",
      "epoch 131: MSE = 1.324771222022395, lr = 122.84328811854556\n",
      "epoch 132: MSE = 1.3244694710230016, lr = 122.59760154230847\n",
      "epoch 133: MSE = 1.3241702184354414, lr = 122.35240633922385\n",
      "epoch 134: MSE = 1.3238733972653869, lr = 122.1077015265454\n",
      "epoch 135: MSE = 1.3235789424141702, lr = 121.86348612349231\n",
      "epoch 136: MSE = 1.3232867906131978, lr = 121.61975915124532\n",
      "epoch 137: MSE = 1.3229968803610967, lr = 121.37651963294283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138: MSE = 1.3227091518634704, lr = 121.13376659367694\n",
      "epoch 139: MSE = 1.3224235469751466, lr = 120.89149906048958\n",
      "epoch 140: MSE = 1.3221400091447908, lr = 120.6497160623686\n",
      "epoch 141: MSE = 1.321858483361789, lr = 120.40841663024386\n",
      "epoch 142: MSE = 1.321578916105289, lr = 120.16759979698338\n",
      "epoch 143: MSE = 1.3213012552952934, lr = 119.92726459738941\n",
      "epoch 144: MSE = 1.3210254502457341, lr = 119.68741006819464\n",
      "epoch 145: MSE = 1.3207514516194174, lr = 119.44803524805825\n",
      "epoch 146: MSE = 1.3204792113847592, lr = 119.20913917756214\n",
      "epoch 147: MSE = 1.320208682774251, lr = 118.97072089920701\n",
      "epoch 148: MSE = 1.3199398202445494, lr = 118.7327794574086\n",
      "epoch 149: MSE = 1.3196725794381399, lr = 118.49531389849378\n",
      "epoch 150: MSE = 1.3194069171465046, lr = 118.25832327069679\n",
      "epoch 151: MSE = 1.3191427912747051, lr = 118.0218066241554\n",
      "epoch 152: MSE = 1.3188801608073635, lr = 117.78576301090709\n",
      "epoch 153: MSE = 1.3186189857759336, lr = 117.55019148488527\n",
      "epoch 154: MSE = 1.3183592272272393, lr = 117.3150911019155\n",
      "epoch 155: MSE = 1.3181008471932114, lr = 117.08046091971167\n",
      "epoch 156: MSE = 1.3178438086617854, lr = 116.84629999787225\n",
      "epoch 157: MSE = 1.3175880755488876, lr = 116.6126073978765\n",
      "epoch 158: MSE = 1.31733361267149, lr = 116.37938218308075\n",
      "epoch 159: MSE = 1.3170803857216788, lr = 116.14662341871458\n",
      "epoch 160: MSE = 1.3168283612416865, lr = 115.91433017187715\n",
      "epoch 161: MSE = 1.3165775065998577, lr = 115.6825015115334\n",
      "epoch 162: MSE = 1.3163277899675103, lr = 115.45113650851033\n",
      "epoch 163: MSE = 1.3160791802966503, lr = 115.22023423549331\n",
      "epoch 164: MSE = 1.3158316472985072, lr = 114.98979376702232\n",
      "epoch 165: MSE = 1.315585161422858, lr = 114.75981417948827\n",
      "epoch 166: MSE = 1.3153396938381021, lr = 114.5302945511293\n",
      "epoch 167: MSE = 1.3150952164120722, lr = 114.30123396202704\n",
      "epoch 168: MSE = 1.3148517016935297, lr = 114.07263149410299\n",
      "epoch 169: MSE = 1.3146091228943297, lr = 113.84448623111479\n",
      "epoch 170: MSE = 1.3143674538722365, lr = 113.61679725865255\n",
      "epoch 171: MSE = 1.3141266691143416, lr = 113.38956366413525\n",
      "epoch 172: MSE = 1.3138867437210848, lr = 113.16278453680698\n",
      "epoch 173: MSE = 1.3136476533908321, lr = 112.93645896773337\n",
      "epoch 174: MSE = 1.3134093744050075, lr = 112.71058604979791\n",
      "epoch 175: MSE = 1.313171883613744, lr = 112.48516487769831\n",
      "epoch 176: MSE = 1.3129351584220383, lr = 112.26019454794292\n",
      "epoch 177: MSE = 1.3126991767763858, lr = 112.03567415884703\n",
      "epoch 178: MSE = 1.3124639171518915, lr = 111.81160281052934\n",
      "epoch 179: MSE = 1.3122293585398084, lr = 111.58797960490828\n",
      "epoch 180: MSE = 1.311995480435518, lr = 111.36480364569847\n",
      "epoch 181: MSE = 1.3117622628269219, lr = 111.14207403840707\n",
      "epoch 182: MSE = 1.3115296861832195, lr = 110.91978989033026\n",
      "epoch 183: MSE = 1.311297731444076, lr = 110.6979503105496\n",
      "epoch 184: MSE = 1.3110663800091487, lr = 110.4765544099285\n",
      "epoch 185: MSE = 1.3108356137279698, lr = 110.25560130110864\n",
      "epoch 186: MSE = 1.3106054148901611, lr = 110.03509009850643\n",
      "epoch 187: MSE = 1.310375766215974, lr = 109.81501991830942\n",
      "epoch 188: MSE = 1.3101466508471447, lr = 109.5953898784728\n",
      "epoch 189: MSE = 1.3099180523380392, lr = 109.37619909871586\n",
      "epoch 190: MSE = 1.3096899546470968, lr = 109.15744670051842\n",
      "epoch 191: MSE = 1.3094623421285418, lr = 108.93913180711738\n",
      "epoch 192: MSE = 1.3092351995243612, lr = 108.72125354350314\n",
      "epoch 193: MSE = 1.3090085119565364, lr = 108.50381103641614\n",
      "epoch 194: MSE = 1.3087822649195222, lr = 108.28680341434331\n",
      "epoch 195: MSE = 1.3085564442729594, lr = 108.07022980751462\n",
      "epoch 196: MSE = 1.3083310362346072, lr = 107.85408934789959\n",
      "epoch 197: MSE = 1.3081060273735012, lr = 107.63838116920378\n",
      "epoch 198: MSE = 1.3078814046033065, lr = 107.42310440686538\n",
      "epoch 199: MSE = 1.3076571551758844, lr = 107.20825819805165\n",
      "epoch 200: MSE = 1.3074332666750355, lr = 106.99384168165555\n",
      "epoch 201: MSE = 1.3072097270104366, lr = 106.77985399829224\n",
      "epoch 202: MSE = 1.3069865244117445, lr = 106.56629429029566\n",
      "epoch 203: MSE = 1.3067636474228772, lr = 106.35316170171507\n",
      "epoch 204: MSE = 1.306541084896447, lr = 106.14045537831164\n",
      "epoch 205: MSE = 1.3063188259883542, lr = 105.92817446755502\n",
      "epoch 206: MSE = 1.3060968601525267, lr = 105.71631811861991\n",
      "epoch 207: MSE = 1.3058751771357997, lr = 105.50488548238268\n",
      "epoch 208: MSE = 1.3056537669729342, lr = 105.29387571141791\n",
      "epoch 209: MSE = 1.3054326199817623, lr = 105.08328795999508\n",
      "epoch 210: MSE = 1.3052117267584578, lr = 104.87312138407509\n",
      "epoch 211: MSE = 1.3049910781729248, lr = 104.66337514130694\n",
      "epoch 212: MSE = 1.3047706653643005, lr = 104.45404839102433\n",
      "epoch 213: MSE = 1.3045504797365646, lr = 104.24514029424228\n",
      "epoch 214: MSE = 1.3043305129542548, lr = 104.0366500136538\n",
      "epoch 215: MSE = 1.3041107569382775, lr = 103.82857671362649\n",
      "epoch 216: MSE = 1.3038912038618138, lr = 103.62091956019924\n",
      "epoch 217: MSE = 1.3036718461463201, lr = 103.41367772107884\n",
      "epoch 218: MSE = 1.3034526764576042, lr = 103.20685036563668\n",
      "epoch 219: MSE = 1.3032336877019928, lr = 103.00043666490541\n",
      "epoch 220: MSE = 1.3030148730225728, lr = 102.7944357915756\n",
      "epoch 221: MSE = 1.3027962257955021, lr = 102.58884691999245\n",
      "epoch 222: MSE = 1.3025777396263976, lr = 102.38366922615246\n",
      "epoch 223: MSE = 1.3023594083467862, lr = 102.17890188770016\n",
      "epoch 224: MSE = 1.3021412260106222, lr = 101.97454408392477\n",
      "epoch 225: MSE = 1.3019231868908574, lr = 101.77059499575692\n",
      "epoch 226: MSE = 1.3017052854760789, lr = 101.56705380576541\n",
      "epoch 227: MSE = 1.3014875164671937, lr = 101.36391969815388\n",
      "epoch 228: MSE = 1.3012698747741633, lr = 101.16119185875758\n",
      "epoch 229: MSE = 1.3010523555127966, lr = 100.95886947504006\n",
      "epoch 230: MSE = 1.3008349540015778, lr = 100.75695173608997\n",
      "epoch 231: MSE = 1.3006176657585429, lr = 100.5554378326178\n",
      "epoch 232: MSE = 1.3004004864981966, lr = 100.35432695695256\n",
      "epoch 233: MSE = 1.3001834121284708, lr = 100.15361830303866\n",
      "epoch 234: MSE = 1.299966438747714, lr = 99.95331106643258\n",
      "epoch 235: MSE = 1.2997495626417193, lr = 99.7534044442997\n",
      "epoch 236: MSE = 1.2995327802807846, lr = 99.5538976354111\n",
      "epoch 237: MSE = 1.2993160883168025, lr = 99.35478984014028\n",
      "epoch 238: MSE = 1.2990994835803809, lr = 99.15608026046\n",
      "epoch 239: MSE = 1.2988829630779875, lr = 98.95776809993909\n",
      "epoch 240: MSE = 1.2986665239891249, lr = 98.75985256373922\n",
      "epoch 241: MSE = 1.2984501636635248, lr = 98.56233285861174\n",
      "epoch 242: MSE = 1.2982338796183686, lr = 98.36520819289451\n",
      "epoch 243: MSE = 1.298017669535528, lr = 98.16847777650872\n",
      "epoch 244: MSE = 1.2978015312588254, lr = 97.9721408209557\n",
      "epoch 245: MSE = 1.297585462791315, lr = 97.77619653931379\n",
      "epoch 246: MSE = 1.2973694622925789, lr = 97.58064414623516\n",
      "epoch 247: MSE = 1.2971535280760436, lr = 97.38548285794269\n",
      "epoch 248: MSE = 1.2969376586063088, lr = 97.1907118922268\n",
      "epoch 249: MSE = 1.296721852496495, lr = 96.99633046844235\n"
     ]
    }
   ],
   "source": [
    "n_features = 15\n",
    "\n",
    "P = np.random.random((n_users,n_features))\n",
    "Q = np.random.random((n_items,n_features))\n",
    "\n",
    "lr = 160\n",
    "l2 = 0.000001\n",
    "\n",
    "#train loop\n",
    "for e in range(250):\n",
    "    P_tau = P[userIds,:]\n",
    "    Q_tau = Q[itemIds,:]\n",
    "    pred = np.sum(P_tau * Q_tau, axis = 1)#np.inner(P_tau, Q_tau)\n",
    "    R_hat = coo_matrix((pred, (userIds, itemIds)), shape=(n_users, n_items))\n",
    "    MSE = np.sum(np.square(ratings - pred))/ratings.shape[0] + l2 * (np.sum(np.square(Q)) + np.sum(np.square(P)))\n",
    "    P -= lr * ((R_hat - R) @ Q)/ratings.shape[0] + l2 * np.square(P)\n",
    "    Q -= lr * ((R_hat - R).T @ P)/ratings.shape[0] + l2 * np.square(Q)\n",
    "    lr *= 0.998\n",
    "    print(f\"epoch {e}: MSE = {MSE}, lr = {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test = test['rating'].values\n",
    "userIds_test = test['userId'].values\n",
    "itemIds_test = test['movieId'].values\n",
    "P_tau = P[userIds_test,:]\n",
    "Q_tau = Q[itemIds_test,:]\n",
    "pred = np.sum(P_tau * Q_tau, axis = 1)\n",
    "MSE_test_MF = np.sum(np.square(ratings_test - pred))/ratings_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning based Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_sz = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "\n",
    "#Create batches\n",
    "for i in range(0, n_samples, batch_sz):\n",
    "    limit =  min(i + batch_sz, n_samples)\n",
    "    users_batch, movies_batch, rates_batch = userIds[i: limit], itemIds[i: limit], ratings[i: limit]\n",
    "    batches.append((torch.tensor(users_batch, dtype=torch.long), torch.tensor(movies_batch, dtype=torch.long),\n",
    "                  torch.tensor(rates_batch, dtype=torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=50, embedding_dropout=0.02, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(nn.Linear(2*n_factors, n_factors*4),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.15),\n",
    "                                nn.Linear(n_factors*4, 2*n_factors),\n",
    "                                nn.ReLU())\n",
    "        self.fc = nn.Linear(n_factors*2, 1)\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, users, movies, minmax=[1,5]):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "\n",
    "        if minmax is not None: #Scale the output to [1,5]\n",
    "            min_rating, max_rating = minmax\n",
    "            out = (max_rating - min_rating)*out + min_rating\n",
    "        return out\n",
    "\n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Initialize embeddings and hidden layers weights with xavier.\n",
    "        \"\"\"\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommenderNet(\n",
       "  (u): Embedding(6744, 20)\n",
       "  (m): Embedding(118697, 20)\n",
       "  (drop): Dropout(p=0.02, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=80, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.15, inplace=False)\n",
       "    (3): Linear(in_features=80, out_features=40, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = RecommenderNet(n_factors = 20, n_users=n_users, n_movies=n_items).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.3, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 = 0.9014084935188293\n",
      "Loss at epoch 1 = 0.7757490873336792\n",
      "Loss at epoch 2 = 0.7329035997390747\n",
      "Loss at epoch 3 = 0.7005599141120911\n",
      "Loss at epoch 4 = 0.6877195835113525\n",
      "Loss at epoch 5 = 0.6744323968887329\n",
      "Loss at epoch 6 = 0.6600192189216614\n",
      "Loss at epoch 7 = 0.6478566527366638\n",
      "Loss at epoch 8 = 0.637294590473175\n",
      "Loss at epoch 9 = 0.6241940855979919\n",
      "Loss at epoch 10 = 0.6077831387519836\n",
      "Loss at epoch 11 = 0.5996001362800598\n",
      "Loss at epoch 12 = 0.5936069488525391\n",
      "Loss at epoch 13 = 0.5903225541114807\n",
      "Loss at epoch 14 = 0.5871611833572388\n",
      "Loss at epoch 15 = 0.5847481489181519\n",
      "Loss at epoch 16 = 0.5822124481201172\n",
      "Loss at epoch 17 = 0.5801677703857422\n",
      "Loss at epoch 18 = 0.5785619020462036\n",
      "Loss at epoch 19 = 0.5775218605995178\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    c = 0\n",
    "    for users_batch, movies_batch, rates_batch in batches:\n",
    "        net.zero_grad()\n",
    "        out = net(users_batch.to(device), movies_batch.to(device), [1, 5]).squeeze()\n",
    "        loss = criterion(rates_batch.to(device), out)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        \n",
    "        c += 1\n",
    "    scheduler.step(loss)\n",
    "    print(\"Loss at epoch {} = {}\".format(epoch, train_loss/c))\n",
    "#     print(\"Last Loss = {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test = test['rating'].values\n",
    "userIds_test = test['userId'].values\n",
    "itemIds_test = test['movieId'].values\n",
    "pred = net.forward(torch.tensor(userIds_test).to(device),torch.tensor(itemIds_test).to(device)).cpu().detach().numpy()\n",
    "pred = np.array([s[0] for s in pred])\n",
    "MSE_test_nn = np.sum(np.square(ratings_test - pred))/ratings_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the Deep learning-based approach and basic Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic Collaborative Filtering model MSE on test dataset = 0.7642871298737126\n",
      "Deep learning model MSE on test dataset = 0.7134742950961608\n"
     ]
    }
   ],
   "source": [
    "print(f\"basic Collaborative Filtering model MSE on test dataset = {MSE_test_MF}\")\n",
    "print(f\"Deep learning model MSE on test dataset = {MSE_test_nn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method that take a user id as an input and return a top 5 recommended movies for that given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(user_id, method = 'MF'):\n",
    "    if method == 'MF':\n",
    "        p = P[user_id]\n",
    "        scores = np.inner(p, Q)\n",
    "    if method == 'NN':\n",
    "        scores = net.forward(torch.tensor([user_id for _ in range(n_items)]).to(device),torch.tensor(list(range(n_items))).to(device)).cpu().detach().numpy()\n",
    "        scores = np.array([s[0] for s in scores])\n",
    "    ids = np.argsort(-np.array(scores))\n",
    "    return ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
